
class MABlock01(nn.Module):
    def __init__(self, network_depth, dim, mlp_ratio=4.):
        super().__init__()
        self.dim = dim
        if dim <=9:
            self.dim =dim
        else:
            self.dim = dim
            
        # MABlock01
        self.norm1 = nn.BatchNorm2d(dim)
        self.Linear1 = nn.Conv2d(dim, dim, 3, stride=1, padding=1, groups=dim, dilation=1, padding_mode='reflect')
        self.mixConv1 = MixConv(dim,[3,5,1],1)
        self.Conv31 = nn.Conv2d(dim, dim, 3, stride=1, padding=1, groups=dim, dilation=1, padding_mode='reflect')
        self.Conv51 = nn.Conv2d(dim, dim, 5, stride=1, padding=2, groups=dim, dilation=1, padding_mode='reflect')
        ########
        self.mixConv2 = MixConv(dim,[3,5,1],1)
        self.Linear2 = nn.Conv2d(dim, dim, 3,stride=1, padding=1, dilation=1)
        self.Conv32 = nn.Conv2d(dim+dim+dim, dim, 3, stride=1, padding=1, groups=dim, dilation=1, padding_mode='reflect')
        self.Conv52 = nn.Conv2d(dim+dim+dim, dim, 5, stride=1, padding=2, groups=dim, dilation=1, padding_mode='reflect')
        self.mixConv3 = MixConv(dim,[3,5,1],1,[3,3,3])
        self.Linear3 = nn.Conv2d(dim, dim, 3,stride=1, padding=1, dilation=1)
        self.Conv33 = nn.Conv2d(dim, dim, 3, stride=1, padding=3, groups=dim, dilation=3, padding_mode='reflect')
        self.Conv53 = nn.Conv2d(dim, dim, 5, stride=1, padding=6, groups=dim, dilation=3, padding_mode='reflect')
        
        self.Linear4 = nn.Conv2d(dim+dim+dim, dim, 1)

        # CEFN01
        self.norm2 = nn.BatchNorm2d(dim)
        self.cemlp = CEFN01(network_depth=network_depth, dim=dim, hidden_features=int(mlp_ratio) * dim, out_features=dim)

    def forward(self, x):
        identity = x
        a = self.norm1(x)
        b = self.Linear1(a)
        x1 = self.mixConv1(b)
        x11 = self.Conv31(b)
        x12 = self.Conv51(b)
        C1 = torch.concatenate((x1, x11,x12), dim=1)
        #C1 = x1* x11*x12
        #C1 = x1+ x11+x12
        x2 = self.mixConv2(C1)
        x2i = self.Linear2(x2)
        
        x21 = self.Conv32(C1)
        x22 = self.Conv52(C1)
        
        x3 = self.mixConv2(x2i)
        x3i = self.Linear3(x3)
        x31 = self.Conv33(x21)
        x32 = self.Conv53(x22)
       
        C2 =torch.concatenate((x3, x31,x32), dim=1)
       # C2 =x3* x31*x32
        #C2 =x3+ x31+x32
        xi = self.Linear4(C2) + identity
        
        identity = x
        xa = self.norm2(xi)
        xb = self.cemlp(xa) + identity
       
        return xi
    
MM = MABlock01(network_depth=2, dim=3,)(y)
print(MM.shape)

output11 = torch.squeeze(MM, 0)
na1 = output11.detach().numpy()
#output1 =np.transpose(output1,axes=[0,2,3,1]).copy()
print(na1.shape)
na1 =np.transpose(na1,axes=[1,2,0])
print(na1.shape)
plt.imshow(na1)
